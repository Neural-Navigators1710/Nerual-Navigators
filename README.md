# ğŸ¤– WRO Future Engineers 2025 â€“ Self-Driving Robot

An intelligent, self-driving robot designed for the **WRO Future Engineers 2025** category. Built to think, adapt, and race through open and obstacle challenges â€” using real-time vision, autonomous decision-making, and multi-mode switching.

> ğŸ’¡ Built with precision. Driven by code.

---

## ğŸš— Features

- ğŸ¯ Lane and wall detection using computer vision
- ğŸ§­ Lap counting and zone recognition
- â›” Obstacle detection and bypass logic
- ğŸš¦ Push-button start and ready LED indication
- ğŸ›‘ Accurate stop in original section after 3 laps
- ğŸ” Seamless mode switching (Open â†” Obstacle Challenge)
- ğŸ”Œ Modular nano-based control for motors and sensors

---

## ğŸš¦ Challenge Entry Points

> Each challenge mode has a separate `main.py` script.

- `main/main_open.py` â€“ Start **Open Challenge** mode
- `main/main_obstacle.py` â€“ Start **Obstacle Challenge** mode
- `main/main_auto.py` â€“ (Optional) Unified logic: switches modes automatically

## ğŸ“ Project Structure

```
Neural-Navigators/
â”‚
â”œâ”€â”€ LICENSE                   # Open-source license (MIT recommended)
â”œâ”€â”€ README.md                 # Project overview, setup, architecture, and credits
â”œâ”€â”€ requirements.txt          # Python dependencies for OpenCV and hardware
â”‚
â”œâ”€â”€ main/                     # Entry points to run different robot modes
â”‚   â”œâ”€â”€ main_open.py          # Open Challenge logic (lane following, lap counting)
â”‚   â”œâ”€â”€ main_obstacle.py      # Obstacle Challenge logic (object detection + path switching)
â”‚   â””â”€â”€ main_auto.py          # Unified mode: auto-switches between open and obstacle
â”‚
â”œâ”€â”€ vision/                   # Computer vision logic (OpenCV)
â”‚   â”œâ”€â”€ lane_detection.py     # Detects lanes, center alignment, curves
â”‚   â””â”€â”€ obstacle_detection.py # Color filtering, shape recognition for obstacle detection
â”‚
â”œâ”€â”€ logic/                    # Core logic and state management
â”‚   â”œâ”€â”€ lap_counter.py        # Tracks laps completed
â”‚   â””â”€â”€ stop_handler.py       # Logic to stop robot in original start section
â”‚
â”œâ”€â”€ hardware/                 # Interfaces for sensors and actuators
â”‚   â”œâ”€â”€ bma250_gyro.py        # Reads rotation data from BMA250 gyro for lap/orientation
â”‚   â”œâ”€â”€ button.py             # Detects push button press to start the robot
â”‚   â””â”€â”€ led_ready.py          # Controls LED indicator for system readiness
â”‚
â”œâ”€â”€ nano/                      # Microcontroller (nano) code in Arduino/C++
â”‚   â”œâ”€â”€ main.ino              # Controls motors and servo based on commands
â”‚   â””â”€â”€ color_sensor.ino      # Reads data from color sensor (e.g., for obstacle shape)
â”‚
â”œâ”€â”€ test/                     # Calibration and debugging scripts
â”‚   â””â”€â”€ test_lane_detect.py   # Standalone script to test lane detection separately
â”‚
â”œâ”€â”€ assets/                   # Visuals for documentation/demo
â”‚   â”œâ”€â”€ robot.jpg             # Picture of your robot
â”‚   â””â”€â”€ field_demo.gif        # GIF or video showing the robot in action
â”‚
â””â”€â”€ docs/                     # Optional diagrams, notes, or rule highlights
    â””â”€â”€ system_flow.png       # System block diagram or flowchart of logic
```

## ğŸ”§ Setup Instructions

1. **Install dependencies** (on Raspberry Pi):

    ```bash
    pip install -r requirements.txt
    ```

2. **Connect hardware**
   - Attach PiCam, push button, and LED
   - Connect nano to motor, servo, and color sensor
   - Optional: use I2C or UART between Pi â†” nano

3. **Start the robot**

    ```bash
    python3 main/main_open.py
    ```

4. **Press the push button** when the LED turns green to begin.

ğŸ” Mode Switching

Your robot can run both challenges from the same repo.

	â€¢	Open Challenge Mode: lane detection + lap tracking
	â€¢	Obstacle Challenge Mode: object detection + path change
Modes are separated to keep things modular and readable.

## ğŸ§  Architecture

| Component      | Role                          |
|----------------|-------------------------------|
| Raspberry Pi   | Brain (vision + control)      |
| PiCam          | Eyes (OpenCV processing)      |
| nano (external) | Muscles (motor/sensor control)|
| Gyro (BMA250)  | Orientation + lap detection   |
| LEDs + Button  | Status & control interface    |

ğŸ‘¨â€ğŸ’» Contributors

Built by [ Nitish Krishna, Ritvik Raghav / Neural Navigators]
For WRO Future Engineers 2025

ğŸ“œ License

This project is open-source under the MIT License.



